{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMsf60Ot5aQbgzIRlSh4+Ez"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":23,"metadata":{"id":"9IkkjaeiOmCW","executionInfo":{"status":"ok","timestamp":1765453103749,"user_tz":-180,"elapsed":15749,"user":{"displayName":"Ğ˜Ñ€Ğ¸Ğ½Ğ° Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ°","userId":"13099233396683157740"}}},"outputs":[],"source":["# Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ±Ğ¸Ğ±Ğ¸Ğ»Ğ¾Ñ‚ĞµĞºĞ¸\n","!pip install ultralytics roboflow --quiet"]},{"cell_type":"code","source":["#Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ±Ğ¸Ğ±Ğ»Ğ¾Ñ‚ĞµĞºĞ¸\n","import os\n","from roboflow import Roboflow\n","from ultralytics import YOLO\n","import cv2\n","import matplotlib.pyplot as plt\n","import os\n","from google.colab import files\n","import shutil"],"metadata":{"id":"Twoct6As2pUD","executionInfo":{"status":"ok","timestamp":1765453103782,"user_tz":-180,"elapsed":18,"user":{"displayName":"Ğ˜Ñ€Ğ¸Ğ½Ğ° Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ°","userId":"13099233396683157740"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["#Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ\n","rf = Roboflow(api_key=\"sfzfWQgbVAN4uhzSfFAs\")\n","project = rf.workspace(\"capston-invasive-plants-dataset\").project(\"invasive-plants\")\n","dataset = project.version(3).download(\"yolov8\")\n","print(f\"\\nĞ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ ÑĞºĞ°Ñ‡Ğ°Ğ½: {dataset.location}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ws6SHxQItFih","executionInfo":{"status":"ok","timestamp":1765453105838,"user_tz":-180,"elapsed":2052,"user":{"displayName":"Ğ˜Ñ€Ğ¸Ğ½Ğ° Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ°","userId":"13099233396683157740"}},"outputId":"d8d3940e-0699-4cf7-a7be-bf05cf6abdcc"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","\n","Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ ÑĞºĞ°Ñ‡Ğ°Ğ½: /content/Invasive-Plants-3\n"]}]},{"cell_type":"code","source":["# ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\n","model = YOLO('yolov8n.pt')\n","\n","train_results = model.train(\n","    data=f\"{dataset.location}/data.yaml\",\n","    epochs=15,\n","    imgsz=640,\n","    batch=16,\n","    name='invasive_detector',\n","    project='/content/runs',\n","    exist_ok=True,\n","    save_dir='/content/runs')"],"metadata":{"id":"TOr7wxdbBQ2H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765471440403,"user_tz":-180,"elapsed":18334562,"user":{"displayName":"Ğ˜Ñ€Ğ¸Ğ½Ğ° Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ°","userId":"13099233396683157740"}},"outputId":"c317923d-ccef-4785-b9b9-4edd57954976"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.235 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Invasive-Plants-3/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=invasive_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/invasive_detector, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=5\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n","Model summary: 129 layers, 3,011,823 parameters, 3,011,807 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 320.4Â±50.2 MB/s, size: 100.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Invasive-Plants-3/train/labels.cache... 1440 images, 142 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1440/1440 1.3Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 307.0Â±45.1 MB/s, size: 93.0 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Invasive-Plants-3/valid/labels.cache... 411 images, 50 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 411/411 461.3Kit/s 0.0s\n","Plotting labels to /content/runs/invasive_detector/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1m/content/runs/invasive_detector\u001b[0m\n","Starting training for 15 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/15         0G      1.507      3.326      1.959         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.4s/it 18:37\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.3s/it 2:00\n","                   all        411        377      0.289      0.325      0.213     0.0543\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/15         0G      1.494      2.753      1.915         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.2s/it 18:21\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.2s/it 1:59\n","                   all        411        377      0.257      0.398      0.221     0.0804\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/15         0G      1.535      2.485      1.927         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.2s/it 18:15\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.0s/it 1:57\n","                   all        411        377      0.353      0.388      0.322      0.123\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/15         0G      1.516      2.302       1.89         44        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.2s/it 18:16\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.8s/it 1:54\n","                   all        411        377      0.639      0.511      0.511      0.244\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/15         0G      1.488      2.132      1.857         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.3s/it 18:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.8s/it 1:55\n","                   all        411        377      0.465      0.488      0.469       0.23\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/15         0G      1.582      2.316       2.26         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.1s/it 18:13\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.0s/it 1:57\n","                   all        411        377      0.448      0.509      0.478      0.246\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/15         0G      1.558      1.971      2.216         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.1s/it 18:12\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.7s/it 1:53\n","                   all        411        377      0.677      0.604      0.641      0.315\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/15         0G      1.505      1.786      2.171         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.2s/it 18:15\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.0s/it 1:57\n","                   all        411        377      0.715       0.57       0.67      0.354\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/15         0G      1.458      1.634      2.098         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.1s/it 18:09\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.1s/it 1:58\n","                   all        411        377      0.704      0.576      0.641      0.328\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/15         0G       1.47      1.583      2.096         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.2s/it 18:21\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.1s/it 1:59\n","                   all        411        377      0.717      0.687      0.727      0.384\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/15         0G      1.429      1.549      2.062         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.2s/it 18:20\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.0s/it 1:57\n","                   all        411        377      0.691      0.668      0.713      0.351\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/15         0G      1.385      1.461      2.039         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.2s/it 18:16\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.3s/it 2:01\n","                   all        411        377      0.736      0.678      0.715      0.394\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/15         0G      1.375      1.386      2.028         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.1s/it 18:05\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.3s/it 2:01\n","                   all        411        377      0.805      0.635      0.732      0.391\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/15         0G      1.317      1.325      1.955         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.1s/it 18:10\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.4s/it 2:02\n","                   all        411        377      0.745      0.727      0.762      0.424\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/15         0G      1.269      1.261      1.904         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 90/90 12.1s/it 18:08\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.3s/it 2:01\n","                   all        411        377      0.751      0.728      0.776      0.432\n","\n","15 epochs completed in 5.061 hours.\n","Optimizer stripped from /content/runs/invasive_detector/weights/last.pt, 6.2MB\n","Optimizer stripped from /content/runs/invasive_detector/weights/best.pt, 6.2MB\n","\n","Validating /content/runs/invasive_detector/weights/best.pt...\n","Ultralytics 8.3.235 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n","Model summary (fused): 72 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.3s/it 1:48\n","                   all        411        377      0.749      0.728      0.776      0.433\n","      Creeping Thistle        103        104      0.735      0.788      0.817      0.416\n","      Himalayan Balsam        114        117      0.758      0.821      0.826      0.382\n","     Japanese Knotweed         28         28      0.734      0.714      0.748      0.572\n","          Leafy Spurge         59         69      0.712      0.609      0.709      0.377\n","    Purple Loosestrife         57         59      0.807      0.709      0.781      0.416\n","Speed: 6.4ms preprocess, 245.0ms inference, 0.0ms loss, 0.6ms postprocess per image\n","Results saved to \u001b[1m/content/runs/invasive_detector\u001b[0m\n"]}]},{"cell_type":"code","source":["# ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ\n","model_src = \"/content/runs/invasive_detector/weights/best.pt\"\n","model_dst = \"/content/invasive_detector_best.pt\"\n","\n","# ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼\n","shutil.copy(model_src, model_dst)\n","\n","# ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ½Ğ° ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€\n","files.download(model_dst)\n","print(f'ĞœĞ¾Ğ´ĞµĞ»ÑŒ invasive_detector_best ÑĞºĞ°Ñ‡Ğ°Ğ½Ğ° Ğ½Ğ° ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€ Ğ² Ğ¿Ğ°Ğ¿ĞºÑƒ Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¾Ğº Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"RaE8nJLEFOVt","executionInfo":{"status":"ok","timestamp":1765472658977,"user_tz":-180,"elapsed":43,"user":{"displayName":"Ğ˜Ñ€Ğ¸Ğ½Ğ° Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ°","userId":"13099233396683157740"}},"outputId":"cbd26636-cd02-4737-92f7-d315676543be"},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_5da75785-1942-4c58-ac19-81e19857adc9\", \"invasive_detector_best.pt\", 6246058)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ĞœĞ¾Ğ´ĞµĞ»ÑŒ invasive_detector_best ÑĞºĞ°Ñ‡Ğ°Ğ½Ğ° Ğ½Ğ° ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€ Ğ² Ğ¿Ğ°Ğ¿ĞºÑƒ Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¾Ğº Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ\n"]}]},{"cell_type":"code","source":["#ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚2\n","rf = Roboflow(api_key=\"sfzfWQgbVAN4uhzSfFAs\")\n","project2 = rf.workspace(\"test-yjlpb\").project(\"hogweed-dataset\")\n","dataset2 = project2.version(9).download(\"yolov8\")\n","print(f\"\\nĞ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ ÑĞºĞ°Ñ‡Ğ°Ğ½: {dataset2.location}\")"],"metadata":{"id":"uYubBIJe2wGq","executionInfo":{"status":"ok","timestamp":1765472669331,"user_tz":-180,"elapsed":2306,"user":{"displayName":"Ğ˜Ñ€Ğ¸Ğ½Ğ° Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ°","userId":"13099233396683157740"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"72582cdb-2b37-4317-b456-9bd7d4cc81c9"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","\n","Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ ÑĞºĞ°Ñ‡Ğ°Ğ½: /content/Hogweed-Dataset-9\n"]}]},{"cell_type":"code","source":["# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¸ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\n","#Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ» Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ Ğ¸ Ğ¿Ğ¾Ğ´Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ² ÑĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ ĞšĞ¾Ğ»Ğ°Ğ±\n","uploaded = files.upload()\n","uploaded_filename = list(uploaded.keys())[0]\n","model_path = f\"/content/{uploaded_filename}\""],"metadata":{"id":"GbFWH1OMvLdm","executionInfo":{"status":"ok","timestamp":1765472715319,"user_tz":-180,"elapsed":41950,"user":{"displayName":"Ğ˜Ñ€Ğ¸Ğ½Ğ° Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ°","userId":"13099233396683157740"}},"colab":{"base_uri":"https://localhost:8080/","height":73},"outputId":"f0773b58-6e7a-4c3c-d183-374579c48a4b"},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-14836c69-504b-4914-8841-b12996033aa2\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-14836c69-504b-4914-8841-b12996033aa2\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving invasive_detector_best.pt to invasive_detector_best (1).pt\n"]}]},{"cell_type":"code","source":["model = YOLO(model_path)\n","\n","results = model.train(\n","    data=f\"{dataset2.location}/data.yaml\",\n","    epochs=15,\n","    imgsz=640,\n","    batch=16,\n","    patience=5,\n","    exist_ok=True,\n","    name='invasive_detector_hogweed',\n","    project='/content/runs',\n","    save_dir='/content/runs')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NIEC-ZhfHC0y","executionInfo":{"status":"ok","timestamp":1765480619410,"user_tz":-180,"elapsed":7884097,"user":{"displayName":"Ğ˜Ñ€Ğ¸Ğ½Ğ° Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ°","userId":"13099233396683157740"}},"outputId":"58b4a407-f164-4e4e-d72b-9fbacb547d96"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["New https://pypi.org/project/ultralytics/8.3.236 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n","Ultralytics 8.3.235 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Hogweed-Dataset-9/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/invasive_detector_best (1).pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=invasive_detector_hogweed, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/invasive_detector_hogweed, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","Overriding model.yaml nc=5 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n","Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 487.3Â±101.5 MB/s, size: 65.0 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Hogweed-Dataset-9/train/labels.cache... 647 images, 239 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 647/647 810.5Kit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 346.6Â±167.8 MB/s, size: 61.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Hogweed-Dataset-9/valid/labels.cache... 93 images, 29 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 114.1Kit/s 0.0s\n","Plotting labels to /content/runs/invasive_detector_hogweed/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1m/content/runs/invasive_detector_hogweed\u001b[0m\n","Starting training for 15 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/15         0G      2.172      3.418      2.177         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.4s/it 8:29\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.9s/it 26.8s\n","                   all         93        184      0.239      0.168      0.103     0.0426\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/15         0G      2.033      3.067      1.959         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.1s/it 8:17\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.5s/it 28.6s\n","                   all         93        184      0.191      0.179     0.0821     0.0237\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/15         0G      1.987      2.904      1.918         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.4s/it 8:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.7s/it 26.2s\n","                   all         93        184      0.374      0.163      0.135     0.0506\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/15         0G      1.956      2.831       1.91         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.1s/it 8:17\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.7s/it 26.2s\n","                   all         93        184      0.219      0.185      0.109     0.0453\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/15         0G      1.881      2.796      1.896         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.1s/it 8:16\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.2s/it 27.6s\n","                   all         93        184      0.169      0.207     0.0897     0.0302\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/15         0G      1.957      2.999       2.05          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.2s/it 8:19\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.0s/it 27.0s\n","                   all         93        184      0.292      0.147      0.106     0.0426\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/15         0G       1.89      2.848      1.964         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.2s/it 8:19\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.5s/it 31.6s\n","                   all         93        184      0.241      0.217      0.155     0.0624\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/15         0G      1.852      2.789      1.973          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 11.8s/it 8:05\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.1s/it 24.4s\n","                   all         93        184      0.334      0.229      0.167     0.0656\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/15         0G      1.805      2.582      1.917         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.0s/it 8:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.9s/it 26.6s\n","                   all         93        184      0.309      0.262      0.186     0.0747\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/15         0G      1.727       2.45      1.795          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.1s/it 8:14\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.9s/it 26.8s\n","                   all         93        184      0.279      0.228      0.148     0.0638\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/15         0G      1.684      2.485      1.805          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.0s/it 8:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.4s/it 25.1s\n","                   all         93        184      0.338      0.253      0.213        0.1\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/15         0G      1.632      2.314      1.728         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.0s/it 8:11\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.3s/it 24.9s\n","                   all         93        184      0.365      0.303      0.225       0.11\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/15         0G      1.567      2.247      1.684          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.1s/it 8:15\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.8s/it 26.3s\n","                   all         93        184      0.437      0.283      0.241      0.115\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/15         0G      1.534       2.15       1.66          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.2s/it 8:19\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.2s/it 30.6s\n","                   all         93        184      0.365      0.283      0.248      0.121\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/15         0G      1.495      2.126      1.637          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 41/41 12.1s/it 8:16\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 8.1s/it 24.4s\n","                   all         93        184      0.371      0.337      0.255      0.121\n","\n","15 epochs completed in 2.182 hours.\n","Optimizer stripped from /content/runs/invasive_detector_hogweed/weights/last.pt, 6.2MB\n","Optimizer stripped from /content/runs/invasive_detector_hogweed/weights/best.pt, 6.2MB\n","\n","Validating /content/runs/invasive_detector_hogweed/weights/best.pt...\n","Ultralytics 8.3.235 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n","Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 7.7s/it 23.1s\n","                   all         93        184      0.374      0.328      0.255      0.121\n","Speed: 2.6ms preprocess, 223.9ms inference, 0.0ms loss, 1.4ms postprocess per image\n","Results saved to \u001b[1m/content/runs/invasive_detector_hogweed\u001b[0m\n"]}]},{"cell_type":"code","source":["# ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ\n","model_src2 = \"/content/runs/invasive_detector_hogweed/weights/best.pt\"\n","model_dst2 = \"/content/hogweed_detector_best.pt\"\n","\n","# ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼\n","shutil.copy(model_src2, model_dst2)\n","\n","# ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ½Ğ° ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€\n","files.download(model_dst2)\n","print(f'ĞœĞ¾Ğ´ĞµĞ»ÑŒ hogweed_detector_best ÑĞºĞ°Ñ‡Ğ°Ğ½Ğ° Ğ½Ğ° ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€ Ğ² Ğ¿Ğ°Ğ¿ĞºÑƒ Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¾Ğº Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"cCRryy38Jz4Y","executionInfo":{"status":"ok","timestamp":1765481649428,"user_tz":-180,"elapsed":43,"user":{"displayName":"Ğ˜Ñ€Ğ¸Ğ½Ğ° Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ°","userId":"13099233396683157740"}},"outputId":"5308513f-eed0-4465-a4b5-5d1c2ee2819b"},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_88c0147c-bb36-4c38-886f-46a8bb91e1ba\", \"hogweed_detector_best.pt\", 6244458)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ĞœĞ¾Ğ´ĞµĞ»ÑŒ hogweed_detector_best ÑĞºĞ°Ñ‡Ğ°Ğ½Ğ° Ğ½Ğ° ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€ Ğ² Ğ¿Ğ°Ğ¿ĞºÑƒ Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¾Ğº Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ\n"]}]},{"cell_type":"code","source":["#Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ invasive_detector_best\n","\n","#Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\n","uploaded = files.upload() #Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¸Ğ· Ğ¿Ğ°Ğ¿ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ hogweed_detector_best\n","uploaded_filename = list(uploaded.keys())[0]\n","model_path = f\"/content/{uploaded_filename}\"\n","model = YOLO(model_path)\n","\n","#Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n","metrics = model.val()\n","Precision=metrics.box.p[0]\n","Recall=metrics.box.r[0]\n","mAP50=metrics.box.map50\n","print(f'\\nĞ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ (Precision): {Precision:.2%} - % Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğ¹')\n","print(f'ĞŸĞ¾Ğ»Ğ½Ğ¾Ñ‚Ğ° (Recall): {Recall:.2%} - % Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑ‚ĞµĞ½Ğ¸Ğ¹')\n","print(f'ĞĞ±Ñ‰Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° (mAP50): {mAP50:.2%}')\n","f1 = 2 * (Precision * Recall) / (Precision + Recall)\n","print(f'\\nF1-Score: {f1:.3f}')"],"metadata":{"id":"gAJbwb7G3g5g","executionInfo":{"status":"ok","timestamp":1765481944846,"user_tz":-180,"elapsed":137816,"user":{"displayName":"Ğ˜Ñ€Ğ¸Ğ½Ğ° Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ°","userId":"13099233396683157740"}},"colab":{"base_uri":"https://localhost:8080/","height":423},"outputId":"7afadfe9-bf37-4083-b906-c17d7436fab1"},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a6286b4b-fb64-4586-83c4-d5021df83742\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a6286b4b-fb64-4586-83c4-d5021df83742\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving invasive_detector_best.pt to invasive_detector_best (2).pt\n","Ultralytics 8.3.235 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n","Model summary (fused): 72 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.1Â±0.0 ms, read: 362.3Â±69.9 MB/s, size: 91.6 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Invasive-Plants-3/valid/labels.cache... 411 images, 50 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 411/411 514.0Kit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 26/26 3.6s/it 1:34\n","                   all        411        377      0.749      0.728      0.776      0.433\n","      Creeping Thistle        103        104      0.735      0.788      0.817      0.416\n","      Himalayan Balsam        114        117      0.758      0.821      0.826      0.382\n","     Japanese Knotweed         28         28      0.734      0.714      0.748      0.572\n","          Leafy Spurge         59         69      0.712      0.609      0.709      0.377\n","    Purple Loosestrife         57         59      0.807      0.709      0.781      0.416\n","Speed: 1.9ms preprocess, 217.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n","Results saved to \u001b[1m/content/runs/detect/val4\u001b[0m\n","\n","Ğ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ (Precision): 73.52% - % Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğ¹\n","ĞŸĞ¾Ğ»Ğ½Ğ¾Ñ‚Ğ° (Recall): 78.85% - % Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑ‚ĞµĞ½Ğ¸Ğ¹\n","ĞĞ±Ñ‰Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° (mAP50): 77.62%\n","\n","F1-Score: 0.761\n"]}]},{"cell_type":"code","source":["#Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ invasive_detector_best\n","\n","#Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\n","uploaded = files.upload() #Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¸Ğ· Ğ¿Ğ°Ğ¿ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ hogweed_detector_best\n","uploaded_filename = list(uploaded.keys())[0]\n","model_path = f\"/content/{uploaded_filename}\"\n","model = YOLO(model_path)\n","\n","#Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n","metrics = model.val()\n","Precision=metrics.box.p[0]\n","Recall=metrics.box.r[0]\n","mAP50=metrics.box.map50\n","print(f'\\nĞ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ (Precision): {Precision:.2%} - % Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğ¹')\n","print(f'ĞŸĞ¾Ğ»Ğ½Ğ¾Ñ‚Ğ° (Recall): {Recall:.2%} - % Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑ‚ĞµĞ½Ğ¸Ğ¹')\n","print(f'ĞĞ±Ñ‰Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° (mAP50): {mAP50:.2%}')\n","f1 = 2 * (Precision * Recall) / (Precision + Recall)\n","print(f'\\nF1-Score: {f1:.3f}')"],"metadata":{"executionInfo":{"status":"ok","timestamp":1765482175982,"user_tz":-180,"elapsed":77856,"user":{"displayName":"Ğ˜Ñ€Ğ¸Ğ½Ğ° Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ°","userId":"13099233396683157740"}},"colab":{"base_uri":"https://localhost:8080/","height":331},"outputId":"9872a85e-f157-4c17-8edc-d8e2430211af","id":"J6Xs0sMz7sXx"},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-35cc7965-610c-4d75-a61a-7f00ef4f0672\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-35cc7965-610c-4d75-a61a-7f00ef4f0672\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving hogweed_detector_best.pt to hogweed_detector_best (4).pt\n","Ultralytics 8.3.235 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n","Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1669.9Â±640.2 MB/s, size: 83.3 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Hogweed-Dataset-9/valid/labels.cache... 93 images, 29 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 132.2Kit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 6/6 3.6s/it 21.8s\n","                   all         93        184      0.374      0.328      0.255      0.121\n","Speed: 2.6ms preprocess, 212.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n","Results saved to \u001b[1m/content/runs/detect/val5\u001b[0m\n","\n","Ğ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ (Precision): 37.39% - % Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğ¹\n","ĞŸĞ¾Ğ»Ğ½Ğ¾Ñ‚Ğ° (Recall): 32.78% - % Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑ‚ĞµĞ½Ğ¸Ğ¹\n","ĞĞ±Ñ‰Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° (mAP50): 25.51%\n","\n","F1-Score: 0.349\n"]}]}]}